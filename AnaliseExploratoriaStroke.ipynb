{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/fedesoriano/stroke-prediction-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67.4k/67.4k [00:00<00:00, 434kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /Users/lelefarias/.cache/kagglehub/datasets/fedesoriano/stroke-prediction-dataset/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"fedesoriano/stroke-prediction-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 -  Analise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justificativa DataSet\n",
    "\n",
    "O DataSet é realacionado ao tema saúde, focado na análise de Acidentes Vascular Cerebral, em inglês 'Stroke'. Com um trabalho bem sucedido é póssivel alertar certos grupos de risco, a fim de redobrar os cuidados e até realizar tratamento preventivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>228.69</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>202.21</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>105.92</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>171.23</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>174.12</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0   9046  67.0             0              1          Yes        Private   \n",
       "1  51676  61.0             0              0          Yes  Self-employed   \n",
       "2  31112  80.0             0              1          Yes        Private   \n",
       "3  60182  49.0             0              0          Yes        Private   \n",
       "4   1665  79.0             1              0          Yes  Self-employed   \n",
       "\n",
       "   avg_glucose_level   smoking_status  stroke  \n",
       "0             228.69  formerly smoked       1  \n",
       "1             202.21     never smoked       1  \n",
       "2             105.92     never smoked       1  \n",
       "3             171.23           smokes       1  \n",
       "4             174.12     never smoked       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stroke_counts = df['stroke'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Definindo estilo\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "sns.barplot(\n",
    "    x=stroke_counts.index,\n",
    "    y=stroke_counts.values,\n",
    "    hue=stroke_counts.index,  # Atribuindo 'x' ao 'hue'\n",
    "    palette='deep',\n",
    "    legend=False  # Desativando a legenda\n",
    ")\n",
    "\n",
    "# Adicionar rótulos e título\n",
    "plt.xlabel('Stroke')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Stroke Distribution')\n",
    "\n",
    "for index, value in enumerate(stroke_counts.values):\n",
    "    plt.text(index, value + 1, f'{value:.1f}%', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigar valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi    201\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar a presença de valores ausentes por coluna\n",
    "valores_ausentes = df.isnull().sum()\n",
    "\n",
    "# Exibir colunas com valores ausentes\n",
    "print(valores_ausentes[valores_ausentes > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   5110\n",
       "gender               5110\n",
       "age                  5110\n",
       "hypertension         5110\n",
       "heart_disease        5110\n",
       "ever_married         5110\n",
       "work_type            5110\n",
       "Residence_type       5110\n",
       "avg_glucose_level    5110\n",
       "bmi                  4909\n",
       "smoking_status       5110\n",
       "stroke               5110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(40)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['stroke'] & df['bmi'].isnull()].stroke.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stroke\n",
       "0    4861\n",
       "1     249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stroke'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aos desconsiderar os dados em bmi estaremos perderdendo quase 1/5 dos dados de stroke. Analisar o p valor de BMI, vulgo sua importancia para a classificação de stroke ou não.\n",
    "\n",
    "#### 🔬 2. Estratégias de Análise:\n",
    "\n",
    "Stroke é uma variável binária (0 ou 1):\n",
    "\n",
    "Para variáveis categóricas:\n",
    "        \n",
    "    Teste Qui-quadrado (chi² test)\n",
    "Para variáveis numéricas contínuas: Teste t de Student (t-test) ou Teste de Mann-Whitney se não normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature  Chi2 Score       p-value\n",
      "2   heart_disease   87.987436  6.587154e-21\n",
      "1    hypertension   75.449498  3.748736e-18\n",
      "3    ever_married   20.622787  5.592648e-06\n",
      "6  smoking_status    3.369423  6.641702e-02\n",
      "4       work_type    2.925901  8.716857e-02\n",
      "5  Residence_type    0.600717  4.383046e-01\n",
      "0          gender    0.239001  6.249287e-01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Variáveis categóricas\n",
    "cat_cols = ['gender', 'hypertension', 'heart_disease', 'ever_married', \n",
    "            'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "# Converter variáveis categóricas para numéricas\n",
    "df_encoded = df.copy()\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for col in cat_cols:\n",
    "    df_encoded[col] = label_encoder.fit_transform(df_encoded[col].astype(str))\n",
    "\n",
    "# Teste Qui-quadrado\n",
    "chi_scores, p_values = chi2(df_encoded[cat_cols], df_encoded['stroke'])\n",
    "\n",
    "# Resultado em DataFrame\n",
    "result_cat = pd.DataFrame({'Feature': cat_cols, 'Chi2 Score': chi_scores, 'p-value': p_values})\n",
    "print(result_cat.sort_values('p-value'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 📌 **Interpretação dos Resultados:**\n",
    "\n",
    "- **`heart_disease`** e **`hypertension`** têm valores extremamente altos, indicando forte associação com `stroke`. Essas variáveis são estatisticamente muito significativas (p-valores extremamente baixos).\n",
    "\n",
    "- **`ever_married`** também possui um valor alto, indicando associação significativa com `stroke`, embora não tão forte quanto as anteriores.\n",
    "\n",
    "- **`smoking_status`** e **`work_type`** têm valores indicando uma associação moderada ou fraca com `stroke` (com p-valores próximos do intervalo 0.05–0.1).\n",
    "\n",
    "- **`Residence_type`** e **`gender`** apresentam valores normalizados baixos, indicando que essas variáveis não têm associação estatisticamente significativa com o evento `stroke` (altos p-valores, bem acima do limite padrão de 0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature     F-Value       P-Value\n",
      "0                age  279.980918  3.655693e-61\n",
      "1  avg_glucose_level   96.585072  1.379969e-22\n",
      "2                bmi    8.826500  2.983269e-03\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Variáveis numéricas\n",
    "num_cols = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "# Removendo linhas com valores ausentes\n",
    "df_clean = df.dropna(subset=num_cols + ['stroke'])\n",
    "\n",
    "# Aplicando ANOVA (f_classif)\n",
    "f_values, p_values = f_classif(df_clean[num_cols], df_clean['stroke'])\n",
    "\n",
    "# Exibindo resultados em DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Feature': num_cols,\n",
    "    'F-Value': f_values,\n",
    "    'P-Value': p_values\n",
    "}).sort_values('P-Value')\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📌 **Interpretação dos Resultados:**\n",
    "\n",
    "- **`age` (p ≈ 3.66e-61)**:\n",
    "  - Apresenta um valor extremamente baixo, indicando uma associação muito forte e estatisticamente significativa com o evento `stroke`. Em outras palavras, a idade é um fator altamente relevante na ocorrência do acidente vascular cerebral.\n",
    "\n",
    "- **`avg_glucose_level` (p ≈ 1.38e-22)**:\n",
    "  - Também apresenta uma associação muito forte, com um p-valor extremamente baixo, sugerindo que níveis mais altos de glicose têm forte relevância estatística na ocorrência do `stroke`.\n",
    "\n",
    "- **`bmi` (p ≈ 2.98e-03)**:\n",
    "  - Possui um p-valor baixo (menor que 0.05), indicando uma associação significativa com o `stroke`, embora muito menos intensa do que as variáveis anteriores. A relevância dessa variável é moderada, mas estatisticamente válida.\n",
    "\n",
    "#### 🚩 **Conclusões e Recomendações:**\n",
    "- **`age`** e **`avg_glucose_level`** devem ser consideradas variáveis-chave em qualquer modelo preditivo ou análise exploratória relacionada ao risco de stroke.\n",
    "- **`bmi`**, embora significativa, tem relevância moderada e pode ser incluída, mas não priorizada em comparação com as outras duas variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como a associação de BMI é modera vou testar dois caminho:\n",
    "\n",
    "        eliminar a coluna BMI e na outra eliminar somente as rows nulas. Como residencia e genereno não foram fatores determinantes, serão desconsiderados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2.1 - Primeira abordagem, sem a  coluna BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['bmi','Residence_type', 'gender'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
       "       'work_type', 'avg_glucose_level', 'smoking_status', 'stroke'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regreção logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1444\n",
      "           1       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.94      1533\n",
      "   macro avg       0.47      0.50      0.49      1533\n",
      "weighted avg       0.89      0.94      0.91      1533\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1444    0]\n",
      " [  89    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lelefarias/Dev/UFCG CODE/cdp/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lelefarias/Dev/UFCG CODE/cdp/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lelefarias/Dev/UFCG CODE/cdp/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Features mais relevantes identificadas anteriormente\n",
    "features = ['age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'avg_glucose_level', 'smoking_status']\n",
    "\n",
    "# Codifique variáveis categóricas\n",
    "label_enc = LabelEncoder()\n",
    "df_clean['ever_married'] = label_enc.fit_transform(df_clean['ever_married'])\n",
    "df_clean['hypertension'] = label_enc.fit_transform(df_clean['hypertension'])\n",
    "df_clean['work_type'] = label_enc.fit_transform(df_clean['work_type'])\n",
    "df_clean['smoking_status'] = label_enc.fit_transform(df_clean['smoking_status'])\n",
    "df_clean['heart_disease'] = label_enc.fit_transform(df_clean['heart_disease'])\n",
    "\n",
    "# Defina X e y\n",
    "X = df_clean[features]\n",
    "y = df_clean['stroke']\n",
    "\n",
    "# Padronização das variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X.loc[:, ['age', 'avg_glucose_level']] = scaler.fit_transform(X[['age', 'avg_glucose_level']])\n",
    "\n",
    "# Divisão treino/teste (70%-30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Treinar o modelo de regressão logística\n",
    "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Fazer predições\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🔍 **Analisando detalhadamente:**\n",
    "\n",
    "#### ✅ **Matriz de confusão:**\n",
    "|                   | Predito = 0 | Predito = 1 |\n",
    "|-------------------|-------------|-------------|\n",
    "| **Real = 0**      | 1444 (TP ✅)| 0 (FN)      |\n",
    "| **Real = 1**      | 89 (FP ❌)  | 0 (TN ❌)    |\n",
    "\n",
    "- **TP (True Positive)**: Casos negativos corretamente classificados como **não-stroke**: **1444**\n",
    "- **FP (False Positive)**: Casos positivos (**stroke**) classificados erroneamente como **não-stroke**: **89**\n",
    "- O modelo não identificou **nenhum caso positivo (stroke)** corretamente.\n",
    "\n",
    "---\n",
    "\n",
    "#### 📉 **Métricas importantes:**\n",
    "\n",
    "- **Precisão (`precision`)** para classe `stroke = 1`: **0.00**\n",
    "  - O modelo não previu nenhum caso positivo corretamente.\n",
    "\n",
    "- **Recall** para classe `stroke = 1`: **0.00**\n",
    "  - Não detectou nenhum dos casos reais de stroke.\n",
    "\n",
    "- **f1-score** para classe `stroke = 1`: **0.00**\n",
    "  - Consequência das métricas anteriores (nenhuma predição correta).\n",
    "\n",
    "- **Acurácia** geral (**0.94**):  \n",
    "  - Alta, mas enganosa devido ao forte desbalanceamento. O modelo simplesmente prevê que ninguém teve um stroke, acertando a maioria dos casos (não-stroke).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora Balanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.74      0.85      1444\n",
      "           1       0.15      0.74      0.25        89\n",
      "\n",
      "    accuracy                           0.74      1533\n",
      "   macro avg       0.57      0.74      0.55      1533\n",
      "weighted avg       0.93      0.74      0.81      1533\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1074  370]\n",
      " [  23   66]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Features mais relevantes identificadas anteriormente\n",
    "features = ['age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'avg_glucose_level', 'smoking_status']\n",
    "\n",
    "# Codifique variáveis categóricas\n",
    "label_enc = LabelEncoder()\n",
    "df_clean['ever_married'] = label_enc.fit_transform(df_clean['ever_married'])\n",
    "df_clean['hypertension'] = label_enc.fit_transform(df_clean['hypertension'])\n",
    "df_clean['work_type'] = label_enc.fit_transform(df_clean['work_type'])\n",
    "df_clean['smoking_status'] = label_enc.fit_transform(df_clean['smoking_status'])\n",
    "df_clean['heart_disease'] = label_enc.fit_transform(df_clean['heart_disease'])\n",
    "\n",
    "# Defina X e y\n",
    "X = df_clean[features]\n",
    "y = df_clean['stroke']\n",
    "\n",
    "# Padronização das variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X.loc[:, ['age', 'avg_glucose_level']] = scaler.fit_transform(X[['age', 'avg_glucose_level']])\n",
    "\n",
    "# Divisão treino/teste (70%-30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Treinar o modelo de regressão logística\n",
    "logreg = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Fazer predições\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ **Matriz de confusão:**\n",
    "|                   | Predito = 0 | Predito = 1 |\n",
    "|-------------------|-------------|-------------|\n",
    "| **Real = 0**      | 1074 (TP ✅)| 370 (FP ❌)  |\n",
    "| **Real = 1**      | 23 (FN ❌)  | 66 (TN ✅)   |\n",
    "\n",
    "\n",
    "O balanceamento não resolve o problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      1458\n",
      "           1       0.17      0.20      0.18        75\n",
      "\n",
      "    accuracy                           0.91      1533\n",
      "   macro avg       0.56      0.57      0.57      1533\n",
      "weighted avg       0.92      0.91      0.92      1533\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1385   73]\n",
      " [  60   15]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Selecionando features importantes\n",
    "features = ['age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'avg_glucose_level', 'smoking_status']\n",
    "\n",
    "# Codificando variáveis categóricas\n",
    "label_enc = LabelEncoder()\n",
    "df_clean['ever_married'] = label_enc.fit_transform(df_clean['ever_married'])\n",
    "df_clean['hypertension'] = label_enc.fit_transform(df_clean['hypertension'])\n",
    "df_clean['work_type'] = label_enc.fit_transform(df_clean['work_type'])\n",
    "df_clean['smoking_status'] = label_enc.fit_transform(df_clean['smoking_status'])\n",
    "df_clean['heart_disease'] = label_enc.fit_transform(df_clean['heart_disease'])\n",
    "\n",
    "# Definindo X e y\n",
    "X = df_clean[features]\n",
    "y = df_clean['stroke']\n",
    "\n",
    "# Padronização das variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X.loc[:, ['age', 'avg_glucose_level']] = scaler.fit_transform(X[['age', 'avg_glucose_level']])\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Treinando a árvore de decisão (com balanceamento de classes)\n",
    "dtree = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as predições\n",
    "y_pred = dtree.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ **Matriz de confusão:**\n",
    "|                   | Predito = 0 | Predito = 1 |\n",
    "|-------------------|-------------|-------------|\n",
    "| **Real = 0**      | 1385 (TP ✅)| 73 (FP ❌)     |\n",
    "| **Real = 1**      | 60 (FP ❌)  | 15 (TN ✅)    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (KNN):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1458\n",
      "           1       0.29      0.07      0.11        75\n",
      "\n",
      "    accuracy                           0.95      1533\n",
      "   macro avg       0.62      0.53      0.54      1533\n",
      "weighted avg       0.92      0.95      0.93      1533\n",
      "\n",
      "Confusion Matrix (KNN):\n",
      " [[1446   12]\n",
      " [  70    5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Selecionando features importantes\n",
    "features = ['age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'avg_glucose_level', 'smoking_status']\n",
    "\n",
    "# Codificando variáveis categóricas\n",
    "label_enc = LabelEncoder()\n",
    "df_clean['ever_married'] = label_enc.fit_transform(df_clean['ever_married'])\n",
    "df_clean['hypertension'] = label_enc.fit_transform(df_clean['hypertension'])\n",
    "df_clean['work_type'] = label_enc.fit_transform(df_clean['work_type'])\n",
    "df_clean['smoking_status'] = label_enc.fit_transform(df_clean['smoking_status'])\n",
    "df_clean['heart_disease'] = label_enc.fit_transform(df_clean['heart_disease'])\n",
    "\n",
    "# Definindo X e y\n",
    "X = df_clean[features]\n",
    "y = df_clean['stroke']\n",
    "\n",
    "# Padronização das variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X.loc[:, ['age', 'avg_glucose_level']] = scaler.fit_transform(X[['age', 'avg_glucose_level']])\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Treinando o modelo KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # você pode ajustar o valor de k (n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as predições\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "print(\"Classification Report (KNN):\\n\", classification_report(y_test, y_pred_knn))\n",
    "print(\"Confusion Matrix (KNN):\\n\", confusion_matrix(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ **Matriz de confusão:**\n",
    "|                   | Predito = 0 | Predito = 1 |\n",
    "|-------------------|-------------|-------------|\n",
    "| **Real = 0**      | 1446 (TP ✅)| 12 (FP ❌)     |\n",
    "| **Real = 1**      | 70 (FP ❌)  | 5 (TN ✅)    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2.2 - Segunda abordagem, com coluna BMI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regreção logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1401\n",
      "           1       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.95      1473\n",
      "   macro avg       0.48      0.50      0.49      1473\n",
      "weighted avg       0.90      0.95      0.93      1473\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1401    0]\n",
      " [  72    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\", encoding='latin1')\n",
    "df_clean = df.copy().dropna()\n",
    "\n",
    "# Features mais relevantes identificadas anteriormente\n",
    "features = ['age', 'bmi', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'avg_glucose_level', 'smoking_status']\n",
    "\n",
    "# Codifique variáveis categóricas\n",
    "label_enc = LabelEncoder()\n",
    "df_clean['ever_married'] = label_enc.fit_transform(df_clean['ever_married'])\n",
    "df_clean['hypertension'] = label_enc.fit_transform(df_clean['hypertension'])\n",
    "df_clean['work_type'] = label_enc.fit_transform(df_clean['work_type'])\n",
    "df_clean['smoking_status'] = label_enc.fit_transform(df_clean['smoking_status'])\n",
    "df_clean['heart_disease'] = label_enc.fit_transform(df_clean['heart_disease'])\n",
    "\n",
    "# Defina X e y\n",
    "X = df_clean[features]\n",
    "y = df_clean['stroke']\n",
    "\n",
    "# Padronização das variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X.loc[:, ['age', 'avg_glucose_level']] = scaler.fit_transform(X[['age', 'avg_glucose_level']])\n",
    "\n",
    "# Divisão treino/teste (70%-30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Treinar o modelo de regressão logística\n",
    "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Fazer predições\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🔍 **Analisando detalhadamente:**\n",
    "\n",
    "#### ✅ **Matriz de confusão:**\n",
    "|                   | Predito = 0 | Predito = 1 |\n",
    "|-------------------|-------------|-------------|\n",
    "| **Real = 0**      | 1401 (TP ✅)| 0 (FN)      |\n",
    "| **Real = 1**      | 72 (FP ❌)  | 0 (TN ❌)    |\n",
    "\n",
    "\n",
    "- Resultados similires sem a coluna BMI, um modelo não confiavel que prediz 0 para maioria dos casos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora Balanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.73      0.84      1401\n",
      "           1       0.14      0.86      0.24        72\n",
      "\n",
      "    accuracy                           0.74      1473\n",
      "   macro avg       0.57      0.80      0.54      1473\n",
      "weighted avg       0.95      0.74      0.81      1473\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1024  377]\n",
      " [  10   62]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\", encoding='latin1')\n",
    "df_clean = df.copy().dropna()\n",
    "\n",
    "# Features mais relevantes identificadas anteriormente\n",
    "features = ['age', 'bmi', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'avg_glucose_level', 'smoking_status']\n",
    "\n",
    "# Codifique variáveis categóricas\n",
    "label_enc = LabelEncoder()\n",
    "df_clean['ever_married'] = label_enc.fit_transform(df_clean['ever_married'])\n",
    "df_clean['hypertension'] = label_enc.fit_transform(df_clean['hypertension'])\n",
    "df_clean['work_type'] = label_enc.fit_transform(df_clean['work_type'])\n",
    "df_clean['smoking_status'] = label_enc.fit_transform(df_clean['smoking_status'])\n",
    "df_clean['heart_disease'] = label_enc.fit_transform(df_clean['heart_disease'])\n",
    "\n",
    "# Defina X e y\n",
    "X = df_clean[features]\n",
    "y = df_clean['stroke']\n",
    "\n",
    "# Padronização das variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X.loc[:, ['age', 'avg_glucose_level']] = scaler.fit_transform(X[['age', 'avg_glucose_level']])\n",
    "\n",
    "# Divisão treino/teste (70%-30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Treinar o modelo de regressão logística\n",
    "logreg = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Fazer predições\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ **Matriz de confusão:**\n",
    "|                   | Predito = 0 | Predito = 1 |\n",
    "|-------------------|-------------|-------------|\n",
    "| **Real = 0**      | 1024 (TP ✅)| 377 (FP❌)     |\n",
    "| **Real = 1**      | 10 (FN ❌)  | 62 (TN ✅)    |\n",
    "\n",
    "\n",
    "modelo se tornou mais confiavel, agora não presume que todos são não stroke, porem ainda apresenta metricas muito baixas para valor 1, stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1410\n",
      "           1       0.09      0.08      0.08        63\n",
      "\n",
      "    accuracy                           0.93      1473\n",
      "   macro avg       0.52      0.52      0.52      1473\n",
      "weighted avg       0.92      0.93      0.92      1473\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1359   51]\n",
      " [  58    5]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\", encoding='latin1')\n",
    "df_clean = df.copy().dropna()\n",
    "\n",
    "# Selecionando features importantes\n",
    "features = ['age', 'bmi', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'avg_glucose_level', 'smoking_status']\n",
    "\n",
    "# Codificando variáveis categóricas\n",
    "label_enc = LabelEncoder()\n",
    "df_clean['ever_married'] = label_enc.fit_transform(df_clean['ever_married'])\n",
    "df_clean['hypertension'] = label_enc.fit_transform(df_clean['hypertension'])\n",
    "df_clean['work_type'] = label_enc.fit_transform(df_clean['work_type'])\n",
    "df_clean['smoking_status'] = label_enc.fit_transform(df_clean['smoking_status'])\n",
    "df_clean['heart_disease'] = label_enc.fit_transform(df_clean['heart_disease'])\n",
    "\n",
    "# Definindo X e y\n",
    "X = df_clean[features]\n",
    "y = df_clean['stroke']\n",
    "\n",
    "# Padronização das variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X.loc[:, ['age', 'avg_glucose_level']] = scaler.fit_transform(X[['age', 'avg_glucose_level']])\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Treinando a árvore de decisão (com balanceamento de classes)\n",
    "dtree = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as predições\n",
    "y_pred = dtree.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✅ **Matriz de confusão:**\n",
    "|                   | Predito = 0 | Predito = 1 |\n",
    "|-------------------|-------------|-------------|\n",
    "| **Real = 0**      | 1359 (TP ✅)| 51 (FP ❌)     |\n",
    "| **Real = 1**      | 58 (Fn ❌)  |  5 (TN ✅)    |\n",
    "\n",
    "mesmo com uma coluna a mais BMI, ter menos dados classificados como STROKE piorou a perfomae do modelo de Arvore de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (KNN):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1410\n",
      "           1       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.96      1473\n",
      "   macro avg       0.48      0.50      0.49      1473\n",
      "weighted avg       0.92      0.96      0.94      1473\n",
      "\n",
      "Confusion Matrix (KNN):\n",
      " [[1408    2]\n",
      " [  63    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\", encoding='latin1')\n",
    "df_clean = df.copy().dropna()\n",
    "\n",
    "# Selecionando features importantes\n",
    "features = ['age', 'bmi', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'avg_glucose_level', 'smoking_status']\n",
    "\n",
    "# Codificando variáveis categóricas\n",
    "label_enc = LabelEncoder()\n",
    "df_clean['ever_married'] = label_enc.fit_transform(df_clean['ever_married'])\n",
    "df_clean['hypertension'] = label_enc.fit_transform(df_clean['hypertension'])\n",
    "df_clean['work_type'] = label_enc.fit_transform(df_clean['work_type'])\n",
    "df_clean['smoking_status'] = label_enc.fit_transform(df_clean['smoking_status'])\n",
    "df_clean['heart_disease'] = label_enc.fit_transform(df_clean['heart_disease'])\n",
    "\n",
    "# Definindo X e y\n",
    "X = df_clean[features]\n",
    "y = df_clean['stroke']\n",
    "\n",
    "# Padronização das variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X.loc[:, ['age', 'avg_glucose_level']] = scaler.fit_transform(X[['age', 'avg_glucose_level']])\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Treinando o modelo KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # você pode ajustar o valor de k (n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Realizando as predições\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "print(\"Classification Report (KNN):\\n\", classification_report(y_test, y_pred_knn))\n",
    "print(\"Confusion Matrix (KNN):\\n\", confusion_matrix(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ✅🔍 **1. Regressão Logística**\n",
    "\n",
    "### ✔️ Vantagens:\n",
    "- **Interpretação clara e direta**:\n",
    "  - Você pode ver os coeficientes e entender o impacto de cada feature.\n",
    "- **Rápida e eficiente em datasets pequenos/médios**.\n",
    "- **Fácil de regularizar** (`L1`, `L2`) e balancear (`class_weight='balanced'`).\n",
    "- Funciona bem quando a relação entre variáveis é **linear**.\n",
    "- **Boa base de comparação** para outros modelos.\n",
    "\n",
    "### ❌ Limitações:\n",
    "- **Assume linearidade** entre variáveis e a saída — pode não capturar bem padrões complexos.\n",
    "- **Desempenho limitado em problemas não lineares ou com muitas interações entre features**.\n",
    "- Sensível à **multicolinearidade** (features altamente correlacionadas).\n",
    "- Pode **subestimar** relações sutis ou não lineares presentes nos dados.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧊📍 **2. KNN (K-Nearest Neighbors)**\n",
    "\n",
    "### ✔️ Vantagens:\n",
    "- **Modelo não-paramétrico**: não faz suposições sobre a distribuição dos dados.\n",
    "- Simples de implementar e entender.\n",
    "- **Capta relações não lineares** de forma natural.\n",
    "- Pode ser poderoso se os dados forem bem separados e normalizados.\n",
    "\n",
    "### ❌ Limitações:\n",
    "- **Muito sensível ao desbalanceamento** de classes (como no seu caso!).\n",
    "- **Desempenho ruim com dados esparsos ou com muito ruído**.\n",
    "- **Muito custo computacional** em datasets grandes (precisa calcular distância para todos os pontos).\n",
    "- Resultado depende **fortemente da escolha de K e da métrica de distância**.\n",
    "- Difícil de interpretar **por que** uma previsão foi feita (modelo de “caixa preta”).\n",
    "\n",
    "---\n",
    "\n",
    "## 🌳📊 **3. Decision Tree (Árvore de Decisão)**\n",
    "\n",
    "### ✔️ Vantagens:\n",
    "- **Interpretação visual e lógica fácil**: é possível \"seguir o caminho\" da árvore.\n",
    "- **Captura bem relações não lineares e interações entre variáveis**.\n",
    "- Funciona bem com dados mistos (numéricos e categóricos).\n",
    "- Não requer normalização dos dados.\n",
    "- **Pode lidar melhor com features irrelevantes ou redundantes** (via poda).\n",
    "\n",
    "### ❌ Limitações:\n",
    "- **Tende a overfitting**, especialmente com árvores profundas e sem poda.\n",
    "- Sensível a **pequenas variações nos dados** (pode mudar bastante com dados levemente diferentes).\n",
    "- Sozinha, **tem dificuldade com dados desbalanceados**, como mostrado no seu caso.\n",
    "- Pode criar **limites de decisão pouco suaves**, que não generalizam bem.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 **Resumo Comparativo:\n",
    "\n",
    "| Modelo             | Interpretação | Tolerância a Desbalanceamento | Não-linearidade | Overfitting | Desempenho observado |\n",
    "|--------------------|---------------|-------------------------------|-----------------|-------------|----------------------|\n",
    "| Regressão Logística | ✅ Alta       | ✅ Sim (com `balanced`)       | ❌ Não           | 🔘 Baixo     | **Melhor F1**        |\n",
    "| KNN                | ❌ Baixa       | ❌ Ruim (sofre muito)         | ✅ Sim           | 🔘 Médio     | Baixo recall classe 1 |\n",
    "| Decision Tree      | 🔘 Média       | ❌ Limitada (sem ajuste)      | ✅ Sim           | ✅ Alto      | Recall fraco, possível overfitting |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3 - Ensemble Learning\n",
    "\n",
    "- pelos resultados anteriores preferi ter mais dados de STROKE e retirar a coluna BMI para lidar com os nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      1444\n",
      "           1       0.18      0.02      0.04        89\n",
      "\n",
      "    accuracy                           0.94      1533\n",
      "   macro avg       0.56      0.51      0.50      1533\n",
      "weighted avg       0.90      0.94      0.91      1533\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1435    9]\n",
      " [  87    2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Selecionando features importantes\n",
    "features = ['age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "       'work_type', 'avg_glucose_level', 'smoking_status']\n",
    "\n",
    "# Codifique variáveis categóricas\n",
    "label_enc = LabelEncoder()\n",
    "df_clean['ever_married'] = label_enc.fit_transform(df_clean['ever_married'])\n",
    "df_clean['hypertension'] = label_enc.fit_transform(df_clean['hypertension'])\n",
    "df_clean['work_type'] = label_enc.fit_transform(df_clean['work_type'])\n",
    "df_clean['smoking_status'] = label_enc.fit_transform(df_clean['smoking_status'])\n",
    "df_clean['heart_disease'] = label_enc.fit_transform(df_clean['heart_disease'])\n",
    "\n",
    "# Defina X e y\n",
    "X = df_clean[features]\n",
    "y = df_clean['stroke']\n",
    "\n",
    "# Padronização das variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X.loc[:, ['age', 'avg_glucose_level']] = scaler.fit_transform(X[['age', 'avg_glucose_level']])\n",
    "\n",
    "# Divisão treino/teste (70%-30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Treinar o modelo de regressão logística\n",
    "model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (AdaBoost):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.57      0.72      1458\n",
      "           1       0.09      0.87      0.17        75\n",
      "\n",
      "    accuracy                           0.59      1533\n",
      "   macro avg       0.54      0.72      0.45      1533\n",
      "weighted avg       0.94      0.59      0.70      1533\n",
      "\n",
      "Confusion Matrix (AdaBoost):\n",
      " [[834 624]\n",
      " [ 10  65]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hr/0brpjq8x195496zt0bkvsnrw0000gn/T/ipykernel_96085/1258302296.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['age', 'avg_glucose_level']] = scaler.fit_transform(X[['age', 'avg_glucose_level']])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Copiando e preparando os dados\n",
    "df_clean = df.copy()\n",
    "\n",
    "features = ['age', 'hypertension', 'heart_disease', 'ever_married',\n",
    "            'work_type', 'avg_glucose_level', 'smoking_status']\n",
    "\n",
    "# Codificação de variáveis categóricas\n",
    "label_enc = LabelEncoder()\n",
    "df_clean['ever_married'] = label_enc.fit_transform(df_clean['ever_married'])\n",
    "df_clean['hypertension'] = label_enc.fit_transform(df_clean['hypertension'])\n",
    "df_clean['work_type'] = label_enc.fit_transform(df_clean['work_type'])\n",
    "df_clean['smoking_status'] = label_enc.fit_transform(df_clean['smoking_status'])\n",
    "df_clean['heart_disease'] = label_enc.fit_transform(df_clean['heart_disease'])\n",
    "\n",
    "# Separando X e y\n",
    "X = df_clean[features]\n",
    "y = df_clean['stroke']\n",
    "\n",
    "# Padronizando variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "X[['age', 'avg_glucose_level']] = scaler.fit_transform(X[['age', 'avg_glucose_level']])\n",
    "\n",
    "# Divisão treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Criando um modelo base (stump) e aplicando AdaBoost\n",
    "base_model = DecisionTreeClassifier(max_depth=1, class_weight='balanced')  # \"stump\" com balanceamento\n",
    "ada_model = AdaBoostClassifier(estimator=base_model, n_estimators=100, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Predição e avaliação\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report (AdaBoost):\\n\", classification_report(y_test, y_pred_ada))\n",
    "print(\"Confusion Matrix (AdaBoost):\\n\", confusion_matrix(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparação entre modelos feita em tabela a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4 - Análise Comparativa e Discussão\n",
    "\n",
    "\n",
    "### 📊 **Tabela Comparativa dos Modelos**\n",
    "\n",
    "| Modelo                 | Acurácia | Precision (Classe 1)   | Recall (Classe 1)   | F1-Score (Classe 1) |\n",
    "|------------------      |----------|------------------------|---------------------|----------------------|\n",
    "| **Regreção log (balanced)**| **0.74**     | 0.15                   | **0.74**                | **0.25**                 |\n",
    "| Decision Tree          | 0.91     | 0.17                   | 0.20                | 0.18                 |\n",
    "| KNN                    | 0.95     | 0.29                   | 0.07                | 0.11                 |\n",
    "| **AdaBoost**           | 0.59     | 0.09                   | **0.87**            | **0.17**             |\n",
    "| RandomForest           | 0.94     | 0.18                   |  0.02               |  0.04            |\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **1. Melhor Desempenho — Qual abordagem foi melhor?**\n",
    "\n",
    "Depende do que você considera \"melhor\", mas geralmente:\n",
    "\n",
    "- Se o foco é **identificar corretamente a maioria dos casos positivos** (classe 1), o modelo mais importante será o que tiver **maior recall na classe 1**.\n",
    "- Se o foco é equilibrar entre **não errar ao prever** e **não deixar passar casos**, olhamos para o **F1-score**.\n",
    "\n",
    "#### 🔍 Pela análise:\n",
    "- **Maior recall (Classe 1)**: **AdaBoost** com **0.87**\n",
    "- **Maior F1-score (Classe 1)**: **Regressão Logística Balanceada** com **0.25**\n",
    "- **Maior precisão (Classe 1)**: **KNN**, com **0.29** (mas com recall muito baixo)\n",
    "- **Maior acurácia geral**: **KNN** com **0.95** (enganosa, pois ignora a classe minoritária)\n",
    "\n",
    "✅ **Conclusão:**\n",
    "> **A Regressão Logística com `class_weight=balanced` foi o modelo com melhor equilíbrio entre recall e precisão para a classe 1**, mesmo com acurácia menor.  \n",
    "> O **AdaBoost** teve o maior recall, o que pode ser desejável se o custo de *perder um positivo* for alto, mas sua precisão foi muito baixa.\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ **2. Há sinais de overfitting ou underfitting?**\n",
    "\n",
    "- **RandomForest com recall 0.02 e alta acurácia (0.94)**:\n",
    "  - Isso indica **overfitting** à classe majoritária. O modelo aprendeu muito bem os padrões da classe 0, mas ignora a classe 1.\n",
    "\n",
    "- **AdaBoost com baixa acurácia geral (0.59) e alto recall (0.87)**:\n",
    "  - Pode estar **overcorrigindo para detectar positivos**, prevendo demais como 1 → muitos falsos positivos → **underfitting na classe 0**.\n",
    "\n",
    "- **KNN com alta precisão (0.29) e recall baixíssimo (0.07)**:\n",
    "  - **Underfitting** na classe 1 — não está conseguindo identificar quase nenhum caso positivo.\n",
    "\n",
    "✅ **Sinal claro de desbalanceamento afetando todos os modelos**. A regressão logística balanceada encontrou um **compromisso razoável**.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. O modelo mais acurado também é o mais interpretável?**\n",
    "\n",
    "Não para todos os casos, mas neste a afirmação é verdadeira!\n",
    "\n",
    "| Modelo                | Interpretabilidade |\n",
    "|-----------------------|--------------------|\n",
    "| **Regressão Logística** | **Alta** ✅ (coeficientes claros, simples) |\n",
    "| Decision Tree         | Média (visível como árvore, mas cresce rápido) |\n",
    "| KNN                   | Baixa (difícil de interpretar como decide) |\n",
    "| AdaBoost              | Baixa (modelo em ensemble, múltiplas iterações) |\n",
    "| RandomForest          | Baixa (ensemble de árvores, difícil rastrear decisões) |\n",
    "\n",
    "✅ **Regressão Logística** é a mais interpretável e transparente. Ótimo para explicar decisões, identificar influência das variáveis, etc.\n",
    "\n",
    "---\n",
    "\n",
    "###  **4. Como o modelo pode ser usado (ou mal utilizado) em um cenário real?**\n",
    "\n",
    "#### ✔️ **Uso correto:**\n",
    "- Em contextos onde a **classe 1 representa um evento crítico** (ex: fraude, doença rara, falha de sistema), o modelo deve ter **alto recall** — identificar ao máximo os casos reais.\n",
    "- A regressão logística balanceada ou o AdaBoost são úteis aqui.\n",
    "\n",
    "#### ❌ **Uso indevido:**\n",
    "- Se o modelo for usado sem considerar o desbalanceamento, ele pode **ignorar completamente a classe 1** e **dar uma falsa sensação de sucesso** (ex: \"tenho 95% de acurácia!\").\n",
    "- Modelos como RandomForest ou KNN, sem ajuste, **não são confiáveis nesse cenário**.\n",
    "- Usar AdaBoost com alto recall, mas precisão 0.09, pode gerar **muitos falsos alarmes**, o que pode **sobrecarregar equipes, gerar desconfiança no sistema ou até perdas financeiras**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
